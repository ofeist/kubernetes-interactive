Kubernetes 101 workshop - complete hands-on
https://www.youtube.com/watch?v=PN3VqbZqmD8


kubernetes?
- managment of deploymnets and orchestration of containerized apps on the large scale


arch?
15:50 Kubernetes Architecture
---
- control & worker node
command -> API server
- C:: API server (authentication(ID/key), authorization(permission for action), admission(policy))
- C:: scheduler (resources?)
- W:: kubelet (asks API server if anything to run)
- W:: kubelet -> talks to CRI (containerd) (if API says yes)
- W:: containerd = CRI, CNI, CSI
	= Runtime (containerd = Container runtime interface)
	= Network (IPV tables)
		- Network (IPV tables) -> C :: kube proxy
	= Storage Interface
- C:: Controller manager = manages more replicas of the (above mentioned) application
	- reconciliation loop


33:42 YAML manifests in k8s 
---
- key: value pairs
- object -> :
- attributes of an object -> "  " (double space intendation)
- list -> :
- list items -> -
- multi line string -> |
- placeholders -> {{ }}
- variables -> $
- separation of objects -> ---


40:00 imperative vs declerative commands
---
- "kubectl run nginx --image=nginx" -> imperative
- YAML -> declerative
- GVR = Group, Version, Resource


44:17 killercoda demos
---
- killercoda.com/dashboard
kubectl get nodes
kubectl get pods -A
kubectl get pods -A -o wide
kubectl run nginx --image=nginx
kubectl get pods
kubectl run demo --image=nginx --dry-run=client -oyaml


54:46 What are namespaces?
---
- isolation of environment
- kubectl get ns
- 4 namespaces
	- default
	- kube-node-lease
	- kube-public
	- kube-system
		- local-path-storage ???
- kubectl get pods -n kube-system
- kubectl cluster-info
- kubectl get lease -n kube-node-lease


54:46 What are namespaces? 
---
- isolation of environments
- kubectl get namespace
- kubectl get ns
- kubectl api-resources
- kubectl api-resources --namespaced=false

01:00:36 GitHub repo
---
https://github.com/kubesimplify/workshops-content/tree/main/kubernetes-101


namespaces
---
kubectl create ns dev
kubectl create deploy saiyam --image=nginx
kubectl create deploy saiyam --image=nginx -n dev
kubectl describe ns dev
kubectl delete ns testing

imperative way
	kubectl create deploy saiyam --image=nginx
declerative way
	kubectl create ns demo --dry-run=client -oyaml

apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: null
  name: demo
spec: {}
status: {}

- spec would then contain qouta limit etc.



01:03:44 changing contexts in namespaces 
---
kubectl config set-context --curent --namespace=dev

other cmnds:
kubens
kubectx
?


01:04:23 labels and selectors
---
kubectl get pods --show-labels
kubectl label pod nginx live=demo

- equiti based selector
	- nodeSelector

- set based labels
	- in, notIn, exists

kubectl run nginx --image=nginx
kubectl create deploy nginx --image=nginx
kubectl label pod nginx app=demo

kubectl get pods -l run=nginx
kubectl get pods -l 'app in (demo,nginx)'

- init container section



01:12:00 Pods in Kubernetes
---
i k8s anything that you run, run as pods

kubectl run saiyam --image=nginx
kubectl describe pod saiyam
kubectl logs -f saiyam
kubectl get pods
kubectl delete pod nginxnamesp
kubectl exec -it saiyam -- sh
	exit
kubectl delete pod saiyam --force



01:20:00 Pod lifecycle
---

 
01:21:48 Init container & multi container
---
init container
	-> precondition container, runs before any other container
	-> more init containers possible
	-> to prepare environment for the app (mount volumes etc.)


vi init
	-> copy {init container} into init file
kubectl apply -f init
kubectl get pods
	kubectl get pods -n default
kubectl logs -f init-demo1
kubectl exec -it saiyam -- sh


multiple init conatiner (1.30.25)
--
vi multi
	- copy content into multi file
kubectl apply -f multy
kubectl describe pod init-demo2

- first container started and waiting for services

vi svc
kubectl create -f svc	
	- actually the lower one worked
	- kubectl apply -f 


multi container
--
e.g. sidecar proxy
	- logs from the main app

vi mc.yml
kubectl apply -f mc.yml
kubectl exec -it multi-container -- curl localhost
kubectl describe pods
kubectl describe pods multi-container
kubectl logs -f multi-container -c nginx-container	# how to see the logs of cnginx-container
kubectl exec -it multi-container -c nginx-container -- curl localhost



01:40:56 Probes 
---
kubectp create -f cp
kubectl get pods
kubectl get pods -owide
kubectl describe pod nginx

--
	Warning  Unhealthy  0s (x3 over 20s)  kubelet            Liveness probe failed: HTTP probe failed with statuscode: 404
  Normal   Killing    0s                kubelet            Container nginx failed liveness probe, will be restarted
--


controlplane $ kubectl get pods       
NAME    READY   STATUS    RESTARTS      AGE
nginx   1/1     Running   3 (10s ago)   101
--


01:55:45 Request & limits 
---
-metrics server & resources
(Resource request demo)

kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl get pods -A # get pods froma all namespaces
# this doesn't run

kubectl delete -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

curl -O https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# add- --kubelet-insecure-tls
# vi rr
kubectl top pods


# kubectl top nodes
controlplane $ kubectl top pods
NAME         CPU(cores)   MEMORY(bytes)   
limit-test   965m         0Mi      

-> CPU limit is 1



02:00:30 break
---



02:14:44 Recap
---
https://github.com/kubesimplify/workshops-content/tree/main/kubernetes-101



02:22:17 Deployments & replicasets
---
- deployment is a k8s object that creates a replica set
- spec setion defines "replicas: x"
- RollingUpdateStrategy-> 25% max unavailable, 25% max surge

kubectl create deploy nginx --image=nginx
kubectl get deploy
kubectl get rs
kubectl get pods
kubectl scale deploy nginx --replicas 5

kubectl edit deploy nginx	# change to replicas: 3

kubectl set image deployment/nginx nginx=nginx:1.15.2 --record

kubectl describe deploy

kubectl set image deployment/nginx nginx=saiyam --record
kubectl get pods
kubectl rollout status

kubectl rollout status deploy nginx

kubectl rollout history deployment nginx
kubectl rollout undo deployment nginx --to-revision 1
kubectl rollout history deployment nginx

kubectl delete deploy nginx --force
kubectl get deploy
kubectl get rs



02:35:40 Statefulsets
---
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.22/deploy/local-path-storage.yaml

kubectl exec -it web-0
curl web-0.nginx.default.svc.cluster.local
cat /etc/resolv.conf
curl web-0.nginx



02:49:00 k8s networking 
---
- create a pod
- ina a pod, there is always the "pause" container which holds the namespace
ip netns list	# list the namespaces

ssh node01
ip netns list
lsns
lsns | grep nginx
lsns -p 44400	# list of namespaces from process 44400

4026532375 net         4 44279 65535 /pause
4026532497 uts         4 44279 65535 /pause
4026532498 ipc         4 44279 65535 /pause

net, uts, ipc -> are held by the pause container

ls -lt /var/run/net	# sort and get the most recent namespace
- the lates namespace created is "cni-5eabcf9f-f323-59cd-e630-b4921b36c54d"
- and this one cni-530bb3cb-ea81-4e17-a0c5-7a5e77ad4373

ip netns exec cni-5eabcf9f-f323-59cd-e630-b4921b36c54d ip link

kubectl exec -it -- bash	# on the control node (controlplane)
kubectl exec -it shared-namespace -- sh
- you have now e.g. " eth0@if13:"

- there are "eth" pairs between ETH of pod & vETH node namespaces


internode pod communication
---
ARP can be used (on the same node) as destination is on the same node


node to node communication
---
ARP can not be used between more different nodes

- to check if destionation is on the same network, bitwise or Adding operation is performed
  |
- find the default dateway from ARP
  |
- send to default gateway
  |
- default interface of other node


- services use iptables and netfilter



03:06:35 Services in Kubernetes
---
4 types:
- ClusterIP (default)
	- loadBalancer is needed to get Ingress from outside world
- NodePort
	- direct from outside to a static port on the node
	--type=NodePort
	- accessible @ NodeIp: NodePort
- HeadLess
	- clusterIP: None # you have to specify this
	- 4 statefull sets


kubectl delete statefulset --all --force
kubectl delete pods --all
kubectl delete pods --all --force
kubectl delete svc nginx
kubectl get svc	#none
# we're in clean state now


kubectl run nginx --image=nginx
kubectl run nginx2 --image=nginx
kubectl label pod nginx2 run=nginx --overwrite

kubectl get pods --show-labels

kubectl expose pod nginx --port 80 --dry-run=client -oyaml
kubectl expose pod nginx --port 80

kubectl get ep
kubectl get pods -owide --show-labels

curl 10.111.31.176	# but i can not access this from outside world

kubectl edit svc nginx
# change the service type ClusterIp -> NodePort

# go to traffic/ports and access the port (32117 e.g.)
# nginx is now accessible from outside world



03:17:42 AAA (authn, authz, admission)
---



03:19:36 RBAC 
---
role-based access control

- cluster resources
	- cluster roles
		- can be bound to a role
	- cluster binding
- namespaces resources
	- role
	- can only be bound to a role binding
	- role binding

- role is created
	- definition
		- the verbs: list, get
		- the objects: pod, deployment
	- in service acount you do the role binding
		- SA + Role

- authentication
--
- 3 types:
	1] cacert
	2] user/client key
	3] Service Account token

1] cacert
--

kubectl config view
CLUSTER_NAME=$(kubectl config view -o jsonpath='{$.clusters[0].name}')		# export CLUSTER_NAME=kubernetes
export APISERVER=$(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')
# https://jsonpath.com/

curl --cacert /etc/kubernetes/pki/ca.crt $APISERVER/version


2] user/client key
--

curl --cacert /etc/kubernetes/pki/ca.crt $APISERVER/version/deployments		# forbidden / unauthorized

# this will not work
curl --cacert /etc/kubernetes/pki/ca.crt --cert client --key key $APISERVER/apis/apps/v1/deployments

# the key needs to be created first

# first get the key & client
cat ~/.kube/config

# echo base64 client & key
echo "____client_key____" | base64 -d 
echo "<client-key-data_from kubeconfig>" | base64 -d > key

# this will NOW work!!
curl --cacert /etc/kubernetes/pki/ca.crt --cert client --key key $APISERVER/apis/apps/v1/deployments


3] SA token
--

TOKEN=$(kubectl create token default)
curl --cacert /etc/kubernetes/pki/ca.crt $APISERVER/apis/apps/v1 --header "Authorization: Bearer $TOKEN"


# an example for creating a cluster role, SA and binding
# @ 03:26:07
1] create service account (SA)
2] create cluster-role-binding





03:32:30 Configmaps & Secrets
---
cat << EOF | kubectl apply -f -
#copy paste the content
apiVersion: v1
metadata:
  name: demo-vol
kind: ConfigMap
data:
  fileA: |-
    hello: saiyam
    learn: kubernete
  fileB: test2
EOF
:)

kubectl exec --it busybox2 -- sh

# create secret
kubectl create secret generic test --from-literal=live=demo
kubectl get secret
kubectl get secret -oyaml

kubectl delete pods --all











 
 






03:45:46 Local k8s setup 
03:53:03 Message from Saiyam






















